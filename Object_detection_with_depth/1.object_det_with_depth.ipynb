{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#python verion 3.12.0 --> create environment \n",
    "import cv2\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "import supervision as sv\n",
    "\n",
    "# Load YOLO model\n",
    "model = YOLO('yolov8s-world.pt')\n",
    "classes = ['Person','Mobile','Index Finger','Helmet','Safety Shoes']\n",
    "model.set_classes(classes)\n",
    "\n",
    "BOUNDING_BOX_ANNOTATOR = sv.BoundingBoxAnnotator(thickness=2)\n",
    "LABEL_ANNOTATOR = sv.LabelAnnotator(text_thickness=2, text_scale=1, text_color=sv.Color.BLACK)\n",
    "\n",
    "# Constants\n",
    "KNOWN_DISTANCE = 30  # Inches\n",
    "KNOWN_WIDTH = 5.7  # Inches\n",
    "DISTANCE_LEVEL = 0\n",
    "\n",
    "# Colors\n",
    "GREEN = (0, 255, 0)\n",
    "RED = (0, 0, 255)\n",
    "BLACK = (0, 0, 0)\n",
    "YELLOW = (0, 255, 255)\n",
    "WHITE = (255, 255, 255)\n",
    "CYAN = (255, 255, 0)\n",
    "MAGENTA = (255, 0, 242)\n",
    "GOLDEN = (32, 218, 165)\n",
    "LIGHT_BLUE = (255, 9, 2)\n",
    "PURPLE = (128, 0, 128)\n",
    "CHOCOLATE = (30, 105, 210)\n",
    "PINK = (147, 20, 255)\n",
    "ORANGE = (0, 69, 255)\n",
    "\n",
    "# Fonts\n",
    "font = cv2.FONT_HERSHEY_PLAIN\n",
    "fonts = cv2.FONT_HERSHEY_COMPLEX\n",
    "fonts2 = cv2.FONT_HERSHEY_SCRIPT_SIMPLEX\n",
    "fonts3 = cv2.FONT_HERSHEY_COMPLEX_SMALL\n",
    "fonts4 = cv2.FONT_HERSHEY_TRIPLEX\n",
    "\n",
    "# Load face detection model\n",
    "face_detector = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "\n",
    "def focal_length(measured_distance, real_width, width_in_rf_image):\n",
    "    return (width_in_rf_image * measured_distance) / real_width\n",
    "\n",
    "def distance_finder(focal_length, real_face_width, face_width_in_frame):\n",
    "    return (real_face_width * focal_length) / face_width_in_frame\n",
    "\n",
    "def face_data(image, call_out, distance_level):\n",
    "    if image is None:\n",
    "        raise ValueError(\"Input image is None. Ensure the image is loaded properly.\")\n",
    "    \n",
    "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_detector.detectMultiScale(gray_image, 1.3, 5)\n",
    "\n",
    "    face_width = 0\n",
    "    face_center_x = 0\n",
    "    face_center_y = 0\n",
    "    \n",
    "    for (x, y, h, w) in faces:\n",
    "        line_thickness = 2\n",
    "        LLV = int(h * 0.12)\n",
    "\n",
    "        # Draw bounding box\n",
    "        cv2.line(image, (x, y + LLV), (x + w, y + LLV), GREEN, line_thickness)\n",
    "        cv2.line(image, (x, y + h), (x + w, y + h), GREEN, line_thickness)\n",
    "        cv2.line(image, (x, y + LLV), (x, y + LLV + LLV), GREEN, line_thickness)\n",
    "        cv2.line(image, (x + w, y + LLV), (x + w, y + LLV + LLV), GREEN, line_thickness)\n",
    "        cv2.line(image, (x, y + h), (x, y + h - LLV), GREEN, line_thickness)\n",
    "        cv2.line(image, (x + w, y + h), (x + w, y + h - LLV), GREEN, line_thickness)\n",
    "\n",
    "        face_width = w\n",
    "        face_center_x = int(w / 2) + x\n",
    "        face_center_y = int(h / 2) + y\n",
    "\n",
    "        if distance_level < 10:\n",
    "            distance_level = 10\n",
    "\n",
    "        if call_out:\n",
    "            cv2.line(image, (x, y - 11), (x + distance_level, y - 11), GREEN, 18)\n",
    "\n",
    "    return face_width, faces, face_center_x, face_center_y\n",
    "\n",
    "# Load reference image\n",
    "ref_image = cv2.imread(\"lena (1).png\")\n",
    "if ref_image is None:\n",
    "    print(\"Error: Reference image not loaded. Check the file path.\")\n",
    "else:\n",
    "    ref_image_face_width, _, _, _ = face_data(ref_image, False, DISTANCE_LEVEL)\n",
    "    focal_length_found = focal_length(KNOWN_DISTANCE, KNOWN_WIDTH, ref_image_face_width)\n",
    "    print(f\"Focal Length Found: {focal_length_found}\")\n",
    "\n",
    "def forward(image):\n",
    "    results = model(image, conf=0.05)[0]  # Using YOLO model\n",
    "\n",
    "    # Extract bounding boxes, class IDs, and confidences\n",
    "    boxes = results.boxes.xyxy.cpu().numpy()  # Bounding box coordinates (x1, y1, x2, y2)\n",
    "    class_ids = results.boxes.cls.cpu().numpy().astype(int)  # Class IDs\n",
    "    confidences = results.boxes.conf.cpu().numpy()  # Confidence scores\n",
    "\n",
    "    # Create detections manually\n",
    "    detections = sv.Detections(\n",
    "        xyxy=boxes,\n",
    "        class_id=class_ids,\n",
    "        confidence=confidences\n",
    "    )\n",
    "    \n",
    "    face_width_in_frame, faces, _, _ = face_data(image, True, DISTANCE_LEVEL)\n",
    "\n",
    "    labels = [\n",
    "        f\"{model.names[class_id]} {confidence:0.3f}\"\n",
    "        for class_id, confidence in zip(detections.class_id, detections.confidence)\n",
    "    ]\n",
    "    \n",
    "    for (face_x, face_y, face_w, face_h) in faces:\n",
    "        if face_width_in_frame != 0:\n",
    "            distance = distance_finder(focal_length_found, KNOWN_WIDTH, face_width_in_frame)\n",
    "            distance = round(distance, 2)\n",
    "            cv2.putText(image, f\"Distance {distance} Inches\", (face_x - 6, face_y - 6),\n",
    "                        fonts, 1, GREEN, 2)\n",
    "\n",
    "    annotated_image = image.copy()\n",
    "    annotated_image = BOUNDING_BOX_ANNOTATOR.annotate(annotated_image, detections)\n",
    "    annotated_image = LABEL_ANNOTATOR.annotate(annotated_image, detections, labels=labels)\n",
    "    cv2.imshow('Processed Frame', annotated_image)\n",
    "\n",
    "# Video capture setup\n",
    "cap = cv2.VideoCapture(0)\n",
    "if not cap.isOpened():\n",
    "    print(\"Error: Unable to access the camera.\")\n",
    "else:\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            print(\"Failed to grab frame\")\n",
    "            break\n",
    "\n",
    "        forward(frame)\n",
    "        \n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
